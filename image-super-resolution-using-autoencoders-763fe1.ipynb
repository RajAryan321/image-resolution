{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4328365,"sourceType":"datasetVersion","datasetId":2548969}],"dockerImageVersionId":30158,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport re\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-04T16:56:40.795549Z","iopub.execute_input":"2024-08-04T16:56:40.796200Z","iopub.status.idle":"2024-08-04T16:56:40.802978Z","shell.execute_reply.started":"2024-08-04T16:56:40.796166Z","shell.execute_reply":"2024-08-04T16:56:40.802027Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"base_directory = '../input/image-super-resolution-from-unsplash/Image Super Resolution - Unsplash'\nhires_folder = os.path.join(base_directory, 'high res')\nlowres_folder = os.path.join(base_directory, 'low res')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:56:47.164016Z","iopub.execute_input":"2024-08-04T16:56:47.164426Z","iopub.status.idle":"2024-08-04T16:56:47.170248Z","shell.execute_reply.started":"2024-08-04T16:56:47.164390Z","shell.execute_reply":"2024-08-04T16:56:47.169299Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Image Super Resolution\n- **Image Super Resolution** refers to the task of enhancing the resolution of an image from low-resolution (LR) to high (HR). It is popularly used in the following applications: Surveillance: to detect, identify, and perform facial recognition on low-resolution images obtained from security cameras.\n- Super resolution image reconstruction is to obtain a high-resolution image from a sequence of low-resolution images which are degraded by unknown blur, noise, and down sample.\n\n<div class='alert alert-info'><strong>Note: </strong>The low resolution images are basically images which have a lower width and height and start appearing pixelated when they are upsampled.</div>\n\n<img src='http://www.sfu.ca/~llockhar/assets/images/singleimagesuperresolution.jpg'>\n","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/image-super-resolution-from-unsplash/Image Super Resolution - Unsplash/image_data.csv\")\ndata['low_res'] = data['low_res'].apply(lambda x: os.path.join(lowres_folder,x))\ndata['high_res'] = data['high_res'].apply(lambda x: os.path.join(hires_folder,x))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T16:56:50.918782Z","iopub.execute_input":"2024-08-04T16:56:50.919499Z","iopub.status.idle":"2024-08-04T16:56:50.980987Z","shell.execute_reply.started":"2024-08-04T16:56:50.919457Z","shell.execute_reply":"2024-08-04T16:56:50.980210Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                             low_res  \\\n0  ../input/image-super-resolution-from-unsplash/...   \n1  ../input/image-super-resolution-from-unsplash/...   \n2  ../input/image-super-resolution-from-unsplash/...   \n3  ../input/image-super-resolution-from-unsplash/...   \n4  ../input/image-super-resolution-from-unsplash/...   \n\n                                            high_res  \n0  ../input/image-super-resolution-from-unsplash/...  \n1  ../input/image-super-resolution-from-unsplash/...  \n2  ../input/image-super-resolution-from-unsplash/...  \n3  ../input/image-super-resolution-from-unsplash/...  \n4  ../input/image-super-resolution-from-unsplash/...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>low_res</th>\n      <th>high_res</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/image-super-resolution-from-unsplash/...</td>\n      <td>../input/image-super-resolution-from-unsplash/...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/image-super-resolution-from-unsplash/...</td>\n      <td>../input/image-super-resolution-from-unsplash/...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/image-super-resolution-from-unsplash/...</td>\n      <td>../input/image-super-resolution-from-unsplash/...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/image-super-resolution-from-unsplash/...</td>\n      <td>../input/image-super-resolution-from-unsplash/...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/image-super-resolution-from-unsplash/...</td>\n      <td>../input/image-super-resolution-from-unsplash/...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 4\n\nimage_datagen = ImageDataGenerator(rescale=1./255,validation_split=0.15)\nmask_datagen = ImageDataGenerator(rescale=1./255,validation_split=0.15)\n\ntrain_hiresimage_generator = image_datagen.flow_from_dataframe(\n        data,\n        x_col='high_res',\n        target_size=(800, 1200),\n        class_mode = None,\n        batch_size = batch_size,\n        seed=42,\n        subset='training')\n\ntrain_lowresimage_generator = image_datagen.flow_from_dataframe(\n        data,\n        x_col='low_res',\n        target_size=(800, 1200),\n        class_mode = None,\n        batch_size = batch_size,\n        seed=42,\n        subset='training')\n\nval_hiresimage_generator = image_datagen.flow_from_dataframe(\n        data,\n        x_col='high_res',\n        target_size=(800, 1200),\n        class_mode = None,\n        batch_size = batch_size,\n        seed=42,\n        subset='validation')\n\nval_lowresimage_generator = image_datagen.flow_from_dataframe(\n        data,\n        x_col='low_res',\n        target_size=(800, 1200),\n        class_mode = None,\n        batch_size = batch_size,\n        seed=42,\n        subset='validation')\n\ntrain_generator = zip(train_lowresimage_generator, train_hiresimage_generator)\nval_generator = zip(val_lowresimage_generator, val_hiresimage_generator)\n\ndef imageGenerator(train_generator):\n    for (low_res, hi_res) in train_generator:\n            yield (low_res, hi_res)","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:49:01.551235Z","iopub.execute_input":"2022-10-16T10:49:01.551508Z","iopub.status.idle":"2022-10-16T10:49:05.018552Z","shell.execute_reply.started":"2022-10-16T10:49:01.551477Z","shell.execute_reply":"2022-10-16T10:49:05.01766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization\n- Low Resolution Images and their corresponding High Resolution outputs that we want to predict.","metadata":{}},{"cell_type":"code","source":"n = 0\nfor i,m in train_generator:\n    img,out = i,m\n\n    if n < 5:\n        fig, axs = plt.subplots(1 , 2, figsize=(20,5))\n        axs[0].imshow(img[0])\n        axs[0].set_title('Low Resolution Image')\n        axs[1].imshow(out[0])\n        axs[1].set_title('High Resolution Image')\n        plt.show()\n        n+=1\n    else:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:49:06.664768Z","iopub.execute_input":"2022-10-16T10:49:06.665479Z","iopub.status.idle":"2022-10-16T10:49:12.207635Z","shell.execute_reply.started":"2022-10-16T10:49:06.665441Z","shell.execute_reply":"2022-10-16T10:49:12.206874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Autoencoders \n- Autoencoders are an unsupervised learning technique in which we leverage neural networks for the task of representation learning. Specifically, we'll design a neural network architecture such that we impose a bottleneck in the network which forces a compressed knowledge representation of the original input. \n- As visualized below, we can take an unlabeled dataset and frame it as a supervised learning problem tasked with outputting x_hat, a reconstruction of the original input x.\n\n<div class='alert alert-info'><strong>Note: </strong>Here in our particular case we will try to reconstruct the low resolution images into their corresponding high resolution images.</div>\n\n<img src='https://www.researchgate.net/profile/Xifeng_Guo/publication/320658590/figure/fig1/AS:614154637418504@1523437284408/The-structure-of-proposed-Convolutional-AutoEncoders-CAE-for-MNIST-In-the-middle-there.png'>","metadata":{}},{"cell_type":"code","source":"input_img = Input(shape=(800, 1200, 3))\n\nl1 = Conv2D(64, (3, 3), padding='same', activation='relu')(input_img)\nl2 = Conv2D(64, (3, 3), padding='same', activation='relu')(l1)\nl3 = MaxPooling2D(padding='same')(l2)\nl3 = Dropout(0.3)(l3)\nl4 = Conv2D(128, (3, 3),  padding='same', activation='relu')(l3)\nl5 = Conv2D(128, (3, 3), padding='same', activation='relu')(l4)\nl6 = MaxPooling2D(padding='same')(l5)\nl7 = Conv2D(256, (3, 3), padding='same', activation='relu')(l6)\n\nl8 = UpSampling2D()(l7)\n\nl9 = Conv2D(128, (3, 3), padding='same', activation='relu')(l8)\nl10 = Conv2D(128, (3, 3), padding='same', activation='relu')(l9)\n\nl11 = add([l5, l10])\nl12 = UpSampling2D()(l11)\nl13 = Conv2D(64, (3, 3), padding='same', activation='relu')(l12)\nl14 = Conv2D(64, (3, 3), padding='same', activation='relu')(l13)\n\nl15 = add([l14, l2])\n\ndecoded = Conv2D(3, (3, 3), padding='same', activation='relu')(l15)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:49:25.368665Z","iopub.execute_input":"2022-10-16T10:49:25.369242Z","iopub.status.idle":"2022-10-16T10:49:25.468546Z","shell.execute_reply.started":"2022-10-16T10:49:25.369195Z","shell.execute_reply":"2022-10-16T10:49:25.467873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reconstruction Loss\n\n<img src='https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-09-at-10.20.44-AM.png'>","metadata":{}},{"cell_type":"code","source":"autoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:49:32.261417Z","iopub.execute_input":"2022-10-16T10:49:32.262057Z","iopub.status.idle":"2022-10-16T10:49:32.274271Z","shell.execute_reply.started":"2022-10-16T10:49:32.262017Z","shell.execute_reply":"2022-10-16T10:49:32.273468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training\n<img src='https://cdn.analyticsvidhya.com/wp-content/uploads/2018/04/1IrdJ5PghD9YoOyVAQ73MJw.gif'>","metadata":{}},{"cell_type":"code","source":"train_samples = train_hiresimage_generator.samples\nval_samples = val_hiresimage_generator.samples\n\ntrain_img_gen = imageGenerator(train_generator)\nval_image_gen = imageGenerator(val_generator)","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:53:35.205857Z","iopub.execute_input":"2022-10-16T10:53:35.206726Z","iopub.status.idle":"2022-10-16T10:53:35.212536Z","shell.execute_reply.started":"2022-10-16T10:53:35.206677Z","shell.execute_reply":"2022-10-16T10:53:35.211778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"autoencoder.h5\"\ncheckpoint = ModelCheckpoint(model_path,\n                             monitor=\"val_loss\",\n                             mode=\"min\",\n                             save_best_only = True,\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor = 'val_loss', \n                          min_delta = 0, \n                          patience = 9,\n                          verbose = 1,\n                          restore_best_weights = True)\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                            patience=5, \n                                            verbose=1, \n                                            factor=0.2, \n                                            min_lr=0.00000001)","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:53:36.3218Z","iopub.execute_input":"2022-10-16T10:53:36.322509Z","iopub.status.idle":"2022-10-16T10:53:36.33002Z","shell.execute_reply.started":"2022-10-16T10:53:36.322471Z","shell.execute_reply":"2022-10-16T10:53:36.329272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = autoencoder.fit(train_img_gen,\n                    steps_per_epoch=train_samples//batch_size,\n                    validation_data=val_image_gen,\n                    validation_steps=val_samples//batch_size,\n                    epochs=10, callbacks=[earlystop, checkpoint, learning_rate_reduction])","metadata":{"execution":{"iopub.status.busy":"2022-10-16T10:53:37.587503Z","iopub.execute_input":"2022-10-16T10:53:37.587775Z","iopub.status.idle":"2022-10-16T13:15:00.731569Z","shell.execute_reply.started":"2022-10-16T10:53:37.587744Z","shell.execute_reply":"2022-10-16T13:15:00.730707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference\n\n## Learning Curves","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-16T13:15:00.733457Z","iopub.execute_input":"2022-10-16T13:15:00.733802Z","iopub.status.idle":"2022-10-16T13:15:01.053559Z","shell.execute_reply.started":"2022-10-16T13:15:00.733765Z","shell.execute_reply":"2022-10-16T13:15:01.052796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Results\n- Original Image, Ground Truth Image, Predicted Super Resolution Image","metadata":{}},{"cell_type":"code","source":"n = 0\nfor i,m in val_generator:\n    img,mask = i,m\n    sr1 = autoencoder.predict(img)\n    if n < 20:\n        fig, axs = plt.subplots(1 , 3, figsize=(20,4))\n        axs[0].imshow(img[0])\n        axs[0].set_title('Low Resolution Image')\n        axs[1].imshow(mask[0])\n        axs[1].set_title('High Resolution Image')\n        axs[2].imshow(sr1[0])\n        axs[2].set_title('Predicted High Resolution Image')\n        plt.show()\n        n+=1\n    else:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-10-16T13:15:01.057499Z","iopub.execute_input":"2022-10-16T13:15:01.05776Z","iopub.status.idle":"2022-10-16T13:15:35.1417Z","shell.execute_reply.started":"2022-10-16T13:15:01.057715Z","shell.execute_reply":"2022-10-16T13:15:35.140942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class='alert alert-success'><strong>Conclusion:</strong>\n    <li>The reconstruction loss achieved over here seems to hit a plateau after initial iterations</li>\n    <li>Other variations of autoencoders can be used to improve the generation of high resolution images</li>\n    <li>Conditional GANs can be used as one of the approaches</li>\n</div>","metadata":{}}]}